{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4698 entries, 15 to 5912\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         4698 non-null   datetime64[ns]\n",
      " 1   province                     4698 non-null   object        \n",
      " 2   current_month_consumption    4698 non-null   float64       \n",
      " 3   ARIMA_prediction             4698 non-null   float64       \n",
      " 4   last_year_total_consumption  4698 non-null   float64       \n",
      " 5   rolling_mean_2               4698 non-null   float64       \n",
      " 6   rolling_mean_3               4698 non-null   float64       \n",
      " 7   lag1_monthly_share           4698 non-null   float64       \n",
      " 8   lag2_monthly_share           4698 non-null   float64       \n",
      " 9   lag3_monthly_share           4698 non-null   float64       \n",
      " 10  lag1                         4698 non-null   float64       \n",
      " 11  lag2                         4698 non-null   float64       \n",
      " 12  lag3                         4698 non-null   float64       \n",
      " 13  quarter                      4698 non-null   int64         \n",
      " 14  month                        4698 non-null   int64         \n",
      " 15  covid                        4698 non-null   int64         \n",
      " 16  school_holiday               4698 non-null   int64         \n",
      " 17  population                   4698 non-null   float64       \n",
      " 18  trend                        4698 non-null   float64       \n",
      " 19  yhat_lower                   4698 non-null   float64       \n",
      " 20  yhat_upper                   4698 non-null   float64       \n",
      " 21  yhat                         4698 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(16), int64(4), object(1)\n",
      "memory usage: 844.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# # Save feature_engineered_df \n",
    "# feature_engineered_df.to_csv(\"data/feature_engineered_df.csv\")\n",
    "# # Load feature_engineered_df \n",
    "parse_dates = [\"date\"]\n",
    "feature_engineered_df = pd.read_csv('data/feature_engineered_df.csv', index_col=[0], parse_dates=parse_dates)\n",
    "feature_engineered_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultimate Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range date at train is:  2017-04-01 00:00:00 2021-11-01 00:00:00 with shape of:  (4536, 21)\n",
      "Date range date at test is:  2021-12-01 00:00:00 2021-12-01 00:00:00 with shape of:  (81, 21)\n"
     ]
    }
   ],
   "source": [
    "from src.model_selection.data_preperation import DataPreperation as dp\n",
    "model_df = feature_engineered_df.sort_values(by=[\"date\"]).reset_index(drop=True).copy()\n",
    "main_train, main_test = dp.train_test_split(data=model_df, index_column1=\"date\",index_column2=\"province\",lag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range date at train is:  2017-04-01 00:00:00 2021-10-01 00:00:00 with shape of:  (4455, 21)\n",
      "Date range date at test is:  2021-11-01 00:00:00 2021-11-01 00:00:00 with shape of:  (81, 21)\n",
      "Maximum date at train is:  (Timestamp('2021-10-01 00:00:00'), 'ŞIRNAK')  Shape is:  (4455, 19)\n",
      "Minimum date at train is:  (Timestamp('2017-04-01 00:00:00'), 'ADANA')  Shape is:  (4455, 19)\n",
      "Maximum date at test is:  (Timestamp('2021-11-01 00:00:00'), 'ŞIRNAK')  Shape is:  (81, 19)\n",
      "Minimum date at test is:  (Timestamp('2021-11-01 00:00:00'), 'ADANA')  Shape is:  (81, 19)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = dp.ts_train_test_split(data=main_train.reset_index(),\n",
    "                                                          index_column1=\"date\",\n",
    "                                                          index_column2=\"province\",\n",
    "                                                          lag=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_column1': 'date',\n",
       " 'index_column2': 'province',\n",
       " 'lag': 0,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipeline_params = {\n",
    "    \"estimator_list\":[\"xgboost\",\"lightgbm\",\"catboost\"],\n",
    "    # \"cv\":,\n",
    "    \"estim_params\": {\n",
    "        \"init_params\":\n",
    "                {\n",
    "                \"xgboost__init_params\":{\"objective\":\"reg:gamma\"},\n",
    "                \"lightgbm__init_params\":{\"objective\":\"gamma\"},\n",
    "                \"catboost__init_params\":{}\n",
    "                },\n",
    "        # \"grid_search_params\":value,\n",
    "        # \"fit_params\":value\n",
    "    },\n",
    "    \"scoring\":\"neg_mean_absolute_percantage_error\",\n",
    "    \"gs_train_test_split\":{\"index_column1\":\"date\",\n",
    "                           \"index_column2\":\"province\",\n",
    "                           \"lag\":0, \n",
    "                           \"verbose\": False}\n",
    "}\n",
    "gs_pipeline_params[\"gs_train_test_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range date at train is:  2017-04-01 00:00:00 2021-10-01 00:00:00 with shape of:  (4455, 21)\n",
      "Date range date at test is:  2021-11-01 00:00:00 2021-11-01 00:00:00 with shape of:  (81, 21)\n",
      "Estimators are: ['xgboost', 'lightgbm', 'catboost']\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "def grid_search_pipeline(data: pd.DataFrame, estimator_list: list,\n",
    "                        estim_params: dict, cv: Any=None,\n",
    "                        scoring: str=\"neg_mean_absolute_percantage_error\", **kwargs):\n",
    "    # Grid Search Train Test Split\n",
    "    X_train, y_train, X_test, y_test = dp.ts_train_test_split(data=data.reset_index(),\n",
    "                                                            **kwargs[\"gs_train_test_split\"])\n",
    "    # Get Estimators from the pipeline\n",
    "    estimator_pipeline = make_estimator_pipeline(estimator_list=estimator_list, **estim_params[\"init_params\"])\n",
    "    # print(estim_params[\"init_params\"])\n",
    "def make_estimator_pipeline(estimator_list: list, **kwargs):\n",
    "    estimator_pipeline = dict()\n",
    "    print(\"Estimators are:\",estimator_list)\n",
    "    # print(kwargs)\n",
    "    if \"xgboost\" in estimator_list:\n",
    "        estimator_pipeline[\"xgboost\"] = xgb.XGBRegressor(**kwargs[\"xgboost__init_params\"])\n",
    "        # print(kwargs[\"xgboost__init_params\"])\n",
    "    if \"lightgbm\" in estimator_list:\n",
    "        estimator_pipeline[\"lightgbm\"] = lgb.LGBMRegressor(**kwargs[\"lightgbm__init_params\"])\n",
    "        # print(kwargs[\"lightgbm__init_params\"])\n",
    "    if \"catboost\" in estimator_list:\n",
    "        estimator_pipeline[\"catboost\"] = cbt.CatBoostRegressor(**kwargs[\"catboost__init_params\"])\n",
    "        # print(kwargs[\"catboost__init_params\"])\n",
    "    return estimator_pipeline\n",
    "grid_search_pipeline(data=main_train, **gs_pipeline_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('env38': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f20fb1ed6254620f2d636807022f0ec277b178915348b63e9bfe829f5d63c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
